package main

import (
	"context"
	"fmt"
	"strings"
	"sync/atomic"
	"time"

	"golang.org/x/time/rate"
)

// CrawlJob çˆ¬å–ä»»åŠ¡
type CrawlJob struct {
	BookNumber string
	ChapterNum int
	URL        string
	ResultChan chan ChapterResult
}

// CrawlerNode çˆ¬è™«èŠ‚ç‚¹
type CrawlerNode struct {
	NodeID   string
	Database *Database
	Client   *HTTPClient
	Config   *Config

	hostLimiter *rate.Limiter
	workerPool  chan struct{}
	jobQueue    chan CrawlJob
	shutdown    int32
}

// NewCrawlerNode åˆ›å»ºçˆ¬è™«èŠ‚ç‚¹
func NewCrawlerNode(nodeID string, config *Config) (*CrawlerNode, error) {
	db, err := NewDatabase(config.Database)
	if err != nil {
		return nil, err
	}

	client := NewHTTPClient(config.HTTP)
	hostLimiter := rate.NewLimiter(rate.Limit(config.Crawler.RateLimit), config.Crawler.RateBurst)

	workerPool := make(chan struct{}, config.Crawler.NumWorkers)
	jobQueue := make(chan CrawlJob, config.Crawler.JobQueueSize)

	node := &CrawlerNode{
		NodeID:      nodeID,
		Database:    db,
		Client:      client,
		Config:      config,
		hostLimiter: hostLimiter,
		workerPool:  workerPool,
		jobQueue:    jobQueue,
	}

	for i := 0; i < config.Crawler.NumWorkers; i++ {
		go node.crawlWorker()
	}

	return node, nil
}

// crawlWorker çˆ¬è™«å·¥ä½œåç¨‹
func (node *CrawlerNode) crawlWorker() {
	for job := range node.jobQueue {
		node.hostLimiter.Wait(context.Background())

		title, content, err := node.Client.FetchChapter(
			job.URL,
			job.BookNumber,
			job.ChapterNum,
			node.Config.Crawler.MaxRetries,
			node.Config.Crawler.BaseDelay,
		)

		job.ResultChan <- ChapterResult{
			BookNumber: job.BookNumber,
			ChapterNum: job.ChapterNum,
			Title:      title,
			Content:    content,
			Error:      err,
		}
	}
}

// ProcessBook å¤„ç†æ•´æœ¬ä¹¦
func (node *CrawlerNode) ProcessBook(book *Book) error {
	fmt.Printf("[%s] ğŸ“– å¼€å§‹å¤„ç†ä¹¦ç± %s (å…±%dç« )\n", node.NodeID, book.BookNumber, book.ChapterCount)

	dbSaver := NewAsyncDBSaver(node)
	defer dbSaver.Close()

	resultChan := make(chan ChapterResult, book.ChapterCount)

	var (
		totalCompleted int32
		totalSuccess   int32
		totalFailed    int32
	)

	node.startProgressMonitor(book.ChapterCount, &totalCompleted, &totalSuccess, &totalFailed)

	completedChapters, err := node.Database.GetCompletedChapters(book.BookNumber)
	if err == nil {
		fmt.Printf("[%s] ğŸ“‹ å‘ç°å·²å®Œæˆç« èŠ‚: %d ä¸ªï¼Œè·³è¿‡é‡å¤çˆ¬å–\n", node.NodeID, len(completedChapters))
	}

	go node.dispatchJobs(book, completedChapters, resultChan)

	var chapters []ChapterResult
	successCount := 0
	failedCount := 0

	timeoutDuration := time.Duration(book.ChapterCount/50+30) * time.Second
	if timeoutDuration > 300*time.Second {
		timeoutDuration = 300 * time.Second
	}
	timeout := time.NewTimer(timeoutDuration)
	defer timeout.Stop()

	for i := 0; i < book.ChapterCount; i++ {
		select {
		case result := <-resultChan:
			atomic.AddInt32(&totalCompleted, 1)

			if result.Error != nil {
				atomic.AddInt32(&totalFailed, 1)
				failedCount++
				if failedCount <= 20 {
					fmt.Printf("[%s] âŒ ç« èŠ‚ %s-%d: %v\n", node.NodeID, book.BookNumber, result.ChapterNum, result.Error)
				}

				url := node.Config.GetChapterURL(book.BookNumber, result.ChapterNum)
				node.Database.LogFailedChapter(book.BookNumber, result.ChapterNum, url, result.Error.Error())
				continue
			}

			if result.Content == "å·²å­˜åœ¨" {
				atomic.AddInt32(&totalSuccess, 1)
				successCount++
				continue
			}

			if result.Content == "" {
				atomic.AddInt32(&totalFailed, 1)
				failedCount++
				url := node.Config.GetChapterURL(book.BookNumber, result.ChapterNum)
				node.Database.LogFailedChapter(book.BookNumber, result.ChapterNum, url, "ç« èŠ‚å†…å®¹ä¸ºç©º")
				continue
			}

			atomic.AddInt32(&totalSuccess, 1)
			chapters = append(chapters, result)
			successCount++

			batchSize := node.getBatchSize(book.ChapterCount)
			if len(chapters) >= batchSize {
				dbSaver.Save(chapters)
				chapters = chapters[:0]
			}

		case <-timeout.C:
			fmt.Printf("[%s] â° ä¹¦ç± %s å¤„ç†è¶…æ—¶ï¼Œå·²å®Œæˆ %d/%d ç« \n",
				node.NodeID, book.BookNumber, i, book.ChapterCount)
			goto finish
		}
	}

finish:
	if len(chapters) > 0 {
		fmt.Printf("[%s] ğŸ’¾ ä¿å­˜å‰©ä½™ %d ç« èŠ‚...\n", node.NodeID, len(chapters))
		dbSaver.Save(chapters)
	}

	fmt.Printf("[%s] âœ… ä¹¦ç± %s å¤„ç†å®Œæˆ: %d/%d ç« æˆåŠŸ (æˆåŠŸç‡: %.1f%%)\n",
		node.NodeID, book.BookNumber, successCount, book.ChapterCount,
		float64(successCount)/float64(book.ChapterCount)*100)

	return nil
}

// dispatchJobs åˆ†å‘ä»»åŠ¡
func (node *CrawlerNode) dispatchJobs(book *Book, completedChapters map[int]bool, resultChan chan ChapterResult) {
	for chapterNum := 1; chapterNum <= book.ChapterCount; chapterNum++ {
		if completedChapters[chapterNum] {
			go func(num int) {
				resultChan <- ChapterResult{
					BookNumber: book.BookNumber,
					ChapterNum: num,
					Title:      fmt.Sprintf("ç¬¬%dç« ", num),
					Content:    "å·²å­˜åœ¨",
					Error:      nil,
				}
			}(chapterNum)
			continue
		}

		job := CrawlJob{
			BookNumber: book.BookNumber,
			ChapterNum: chapterNum,
			URL:        node.Config.GetChapterURL(book.BookNumber, chapterNum),
			ResultChan: resultChan,
		}

		select {
		case node.jobQueue <- job:
		default:
			time.Sleep(1 * time.Millisecond)
			node.jobQueue <- job
		}
	}
}

// getBatchSize è·å–æ‰¹æ¬¡å¤§å°
func (node *CrawlerNode) getBatchSize(chapterCount int) int {
	batchSize := node.Config.Crawler.BatchSize
	if chapterCount > 1000 {
		batchSize = 100
	} else if chapterCount < 200 {
		batchSize = 20
	}
	return batchSize
}

// startProgressMonitor å¯åŠ¨è¿›åº¦ç›‘æ§
func (node *CrawlerNode) startProgressMonitor(totalChapters int, completed, success, failed *int32) {
	progressTicker := time.NewTicker(node.Config.Crawler.ProgressTicker)

	var lastCompleted int32
	var lastPrintTime time.Time
	stuckCount := 0

	go func() {
		defer progressTicker.Stop()
		for range progressTicker.C {
			current := atomic.LoadInt32(completed)
			successCount := atomic.LoadInt32(success)
			failedCount := atomic.LoadInt32(failed)

			if current == lastCompleted && current > 0 {
				stuckCount++
				if stuckCount >= 2 {
					fmt.Printf("[%s] âš ï¸  æ£€æµ‹åˆ°æ…¢ä»»åŠ¡é˜»å¡ï¼Œå½“å‰: %d/%d\n",
						node.NodeID, current, totalChapters)
				}
			} else {
				stuckCount = 0
			}

			now := time.Now()
			shouldPrint := current != lastCompleted || now.Sub(lastPrintTime) > 5*time.Second

			if current > 0 && shouldPrint {
				successRate := float64(successCount) / float64(current) * 100
				progress := float64(current) / float64(totalChapters) * 100

				fmt.Printf("[%s] ğŸ“Š è¿›åº¦: %d/%d (%.1f%%) æˆåŠŸ:%d å¤±è´¥:%d æˆåŠŸç‡:%.1f%%\n",
					node.NodeID, current, totalChapters, progress, successCount, failedCount, successRate)

				lastPrintTime = now
			}

			lastCompleted = current

			if current >= int32(totalChapters) {
				break
			}
		}
	}()
}

// RetryFailedChapters æ™ºèƒ½è¡¥çˆ¬å¤±è´¥çš„ç« èŠ‚
func (node *CrawlerNode) RetryFailedChapters() error {
	failures, err := node.Database.GetFailedChapters(50)
	if err != nil {
		return err
	}

	var successCount, skipCount int

	for _, failure := range failures {
		if node.IsShutdown() {
			fmt.Printf("[%s] ğŸ›‘ è¡¥çˆ¬ä¸­æ–­ï¼Œçˆ¬è™«æ­£åœ¨å…³é—­\n", node.NodeID)
			break
		}

		if strings.Contains(failure.ErrorMsg, "ç« èŠ‚ä¸å­˜åœ¨ (404)") {
			skipCount++
			fmt.Printf("[%s] â­ï¸  è·³è¿‡ä¸å­˜åœ¨çš„ç« èŠ‚: %s-%d (404)\n",
				node.NodeID, failure.BookNumber, failure.ChapterNum)
			continue
		}

		if failure.RetryCount > 1 {
			delay := time.Duration(failure.RetryCount) * 2 * time.Second
			time.Sleep(delay)
		}

		fmt.Printf("[%s] ğŸ”„ è¡¥çˆ¬ç« èŠ‚ %s-%d (ç¬¬ %d æ¬¡å°è¯•)\n",
			node.NodeID, failure.BookNumber, failure.ChapterNum, failure.RetryCount+1)

		title, content, err := node.Client.FetchChapter(
			failure.URL,
			failure.BookNumber,
			failure.ChapterNum,
			node.Config.Crawler.MaxRetries,
			node.Config.Crawler.BaseDelay,
		)

		if err == nil && content != "" {
			err = node.Database.SaveChapter(failure.BookNumber, title, content, failure.ChapterNum)
			if err == nil {
				node.Database.RemoveFailedChapter(failure.BookNumber, failure.ChapterNum)
				successCount++
				fmt.Printf("[%s] âœ… è¡¥çˆ¬æˆåŠŸ: %s-%d\n", node.NodeID, failure.BookNumber, failure.ChapterNum)
			} else {
				node.Database.LogFailedChapter(failure.BookNumber, failure.ChapterNum, failure.URL,
					fmt.Sprintf("ä¿å­˜å¤±è´¥: %v", err))
			}
		} else {
			if err != nil {
				node.Database.LogFailedChapter(failure.BookNumber, failure.ChapterNum, failure.URL, err.Error())
			} else {
				node.Database.LogFailedChapter(failure.BookNumber, failure.ChapterNum, failure.URL, "è¡¥çˆ¬åå†…å®¹ä»ä¸ºç©º")
			}
		}

		time.Sleep(100 * time.Millisecond)
	}

	if successCount > 0 || skipCount > 0 {
		fmt.Printf("[%s] ğŸ“Š è¡¥çˆ¬å®Œæˆ: æˆåŠŸ %d ä¸ªï¼Œè·³è¿‡ %d ä¸ªç« èŠ‚\n", node.NodeID, successCount, skipCount)
	} else {
		fmt.Printf("[%s] ğŸ“­ æ²¡æœ‰éœ€è¦è¡¥çˆ¬çš„ç« èŠ‚\n", node.NodeID)
	}

	return nil
}

// SetShutdown è®¾ç½®ä¼˜é›…å…³é—­æ ‡å¿—
func (node *CrawlerNode) SetShutdown() {
	atomic.StoreInt32(&node.shutdown, 1)
	fmt.Printf("[%s] ğŸ“ å·²è®¾ç½®å…³é—­æ ‡å¿—ï¼Œç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ...\n", node.NodeID)
}

// IsShutdown æ£€æŸ¥æ˜¯å¦éœ€è¦å…³é—­
func (node *CrawlerNode) IsShutdown() bool {
	return atomic.LoadInt32(&node.shutdown) == 1
}

// Run è¿è¡Œçˆ¬è™«èŠ‚ç‚¹
func (node *CrawlerNode) Run() {
	fmt.Printf("[%s] çˆ¬è™«èŠ‚ç‚¹å¯åŠ¨\n", node.NodeID)
	fmt.Printf("[%s] ğŸŒ è¿æ¥é…ç½®: å…¨éƒ¨ç›´è¿æ¨¡å¼\n", node.NodeID)

	for {
		if node.IsShutdown() {
			fmt.Printf("[%s] ğŸ›‘ æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œåœæ­¢å¤„ç†æ–°ä»»åŠ¡\n", node.NodeID)
			break
		}

		book, err := node.Database.GetNextTask()
		if err != nil {
			fmt.Printf("[%s] è·å–ä»»åŠ¡å¤±è´¥: %v\n", node.NodeID, err)
			time.Sleep(5 * time.Second)
			continue
		}

		if book == nil {
			fmt.Printf("[%s] æ²¡æœ‰æ›´å¤šä»»åŠ¡ï¼Œå¼€å§‹è¡¥çˆ¬å¤±è´¥ç« èŠ‚\n", node.NodeID)
			if !node.IsShutdown() {
				node.RetryFailedChapters()
			}
			time.Sleep(10 * time.Second)
			continue
		}

		if node.IsShutdown() {
			fmt.Printf("[%s] ğŸ›‘ å…³é—­ä¿¡å·æ£€æµ‹åˆ°ï¼Œè·³è¿‡ä¹¦ç± %s\n", node.NodeID, book.BookNumber)
			break
		}

		fmt.Printf("[%s] ğŸ“– å¼€å§‹å¤„ç†ä¹¦ç± %s (æ”¯æŒä¸­æ–­æ¢å¤)\n", node.NodeID, book.BookNumber)
		err = node.ProcessBook(book)
		success := err == nil

		err = node.Database.MarkBookCompleted(book.BookNumber, success)
		if err != nil {
			fmt.Printf("[%s] æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: %v\n", node.NodeID, err)
		}

		if success {
			fmt.Printf("[%s] âœ… ä¹¦ç± %s å¤„ç†å®Œæˆ\n", node.NodeID, book.BookNumber)
		} else {
			fmt.Printf("[%s] âŒ ä¹¦ç± %s å¤„ç†å¤±è´¥\n", node.NodeID, book.BookNumber)
		}

		if node.IsShutdown() {
			fmt.Printf("[%s] ğŸ›‘ å¤„ç†å®Œå½“å‰ä¹¦ç±ï¼Œå‡†å¤‡å®‰å…¨é€€å‡º\n", node.NodeID)
			break
		}
	}

	fmt.Printf("[%s] ğŸ çˆ¬è™«èŠ‚ç‚¹å·²å®‰å…¨å…³é—­\n", node.NodeID)
}

// Close å…³é—­çˆ¬è™«èŠ‚ç‚¹
func (node *CrawlerNode) Close() error {
	close(node.jobQueue)
	return node.Database.Close()
}
