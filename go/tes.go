package main

import (
	"context"
	"crypto/tls"
	"database/sql"
	"fmt"
	"io/ioutil"
	"net"
	"net/http"
	"os"
	"os/signal"
	"regexp"
	"strings"
	"sync"
	"sync/atomic"
	"syscall"
	"time"

	"golang.org/x/time/rate"

	_ "github.com/go-sql-driver/mysql"
	"golang.org/x/net/http2"
)

// Book ä¹¦ç±ä¿¡æ¯ç»“æ„
type Book struct {
	BookNumber   string
	ChapterCount int
}

// RateLimiter ä¸»æœºçº§é™é€Ÿå™¨
type RateLimiter struct {
	limiter *rate.Limiter
	host    string
}

// CrawlerNode çˆ¬è™«èŠ‚ç‚¹
type CrawlerNode struct {
	NodeID string
	DB     *sql.DB
	Client *http.Client

	// ä¸»æœºçº§é™é€Ÿ (é˜²æ­¢ 403/429)
	hostLimiter *rate.Limiter

	// å›ºå®šWorkeræ± 
	workerPool chan struct{}
	jobQueue   chan CrawlJob

	// ä¼˜é›…å…³é—­æ ‡å¿—
	shutdown int32 // åŸå­æ“ä½œæ ‡å¿—
}

// CrawlJob çˆ¬å–ä»»åŠ¡
type CrawlJob struct {
	BookNumber string
	ChapterNum int
	URL        string
	ResultChan chan ChapterResult
}

// ChapterResult ç« èŠ‚ç»“æœç»“æ„
type ChapterResult struct {
	BookNumber string // æ·»åŠ ä¹¦å·å­—æ®µ
	ChapterNum int
	Title      string
	Content    string
	Error      error
}

// CompiledRegex é¢„ç¼–è¯‘çš„æ­£åˆ™è¡¨è¾¾å¼
var (
	titleRegex    = regexp.MustCompile(`<title>([^_]+)`)
	contentRegex1 = regexp.MustCompile(`(?s)<div[^>]*id=["']chaptercontent["'][^>]*>(.*?)</div>`)
	contentRegex2 = regexp.MustCompile(`(?s)<div[^>]*class=["'][^"']*content[^"']*["'][^>]*>(.*?)</div>`)
	contentRegex3 = regexp.MustCompile(`(?s)<div[^>]*>([^<]{100,}.*?)</div>`)
	htmlTagRegex  = regexp.MustCompile(`<[^>]*>`)
)

// NewCrawlerNode åˆ›å»ºçˆ¬è™«èŠ‚ç‚¹
func NewCrawlerNode(nodeID string) (*CrawlerNode, error) {
	// dsn := "root:123456@tcp(localhost:3306)/novel_db?charset=utf8mb4&parseTime=True&loc=Local&maxAllowedPacket=0"
	dsn := "user_1:Aa123456@tcp(rm-cn-gh64dx1hy0003l5o.rwlb.rds.aliyuncs.com:3306)/novel_db?charset=utf8mb4&parseTime=True&loc=Local&maxAllowedPacket=0"
	db, err := sql.Open("mysql", dsn)
	if err != nil {
		return nil, fmt.Errorf("æ•°æ®åº“è¿æ¥å¤±è´¥: %v", err)
	}

	// é…ç½®æ•°æ®åº“è¿æ¥æ±  - é«˜å¹¶å‘ä¼˜åŒ–
	db.SetMaxOpenConns(200)                 // æœ€å¤§è¿æ¥æ•° 4å€æå‡
	db.SetMaxIdleConns(100)                 // æœ€å¤§ç©ºé—²è¿æ¥æ•° 4å€æå‡
	db.SetConnMaxLifetime(10 * time.Minute) // è¿æ¥æœ€å¤§ç”Ÿå­˜æ—¶é—´

	// åˆ›å»ºç›´è¿HTTPå®¢æˆ·ç«¯ (HTTP/2 + Keep-Alive)
	transport := &http.Transport{
		// è¿æ¥æ± ä¼˜åŒ–
		MaxIdleConns:        1000,
		MaxIdleConnsPerHost: 100,              // å¢å¤§åŒä¸»æœºè¿æ¥æ•°
		MaxConnsPerHost:     200,              // é™åˆ¶æ¯ä¸»æœºæœ€å¤§è¿æ¥
		IdleConnTimeout:     90 * time.Second, // å»¶é•¿ç©ºé—²è¶…æ—¶

		// è¿æ¥å»ºç«‹ä¼˜åŒ–
		DialContext: (&net.Dialer{
			Timeout:   5 * time.Second,
			KeepAlive: 30 * time.Second, // TCP Keep-Alive
		}).DialContext,

		// HTTPä¼˜åŒ–
		DisableKeepAlives:     false,
		DisableCompression:    true, // ç¦ç”¨å‹ç¼©å‡å°‘CPU
		ResponseHeaderTimeout: 10 * time.Second,
		ExpectContinueTimeout: 1 * time.Second,

		// TLSä¼˜åŒ–
		TLSClientConfig: &tls.Config{
			InsecureSkipVerify: true, // è·³è¿‡è¯ä¹¦éªŒè¯åŠ é€Ÿ
		},

		// å¼ºåˆ¶ HTTP/2
		ForceAttemptHTTP2: true,
	}

	// é…ç½® HTTP/2
	http2.ConfigureTransport(transport)

	client := &http.Client{
		Timeout:   15 * time.Second,
		Transport: transport,
	}

	// åˆ›å»ºä¸»æœºçº§é™é€Ÿå™¨ - æ›´ä¿å®ˆçš„è®¾ç½®ä»¥æé«˜ç¨³å®šæ€§
	hostLimiter := rate.NewLimiter(rate.Limit(100), 150) // é™ä½è¯·æ±‚é¢‘ç‡ï¼šæ¯ç§’100è¯·æ±‚ï¼Œçªå‘150

	// å›ºå®šWorkeræ± é…ç½® - ä¿å®ˆè®¾ç½®ä»¥æé«˜ç¨³å®šæ€§
	const numWorkers = 100    // é™ä½åˆ°100ä¸ªworkerï¼Œé¿å…èµ„æºäº‰æŠ¢
	const jobQueueSize = 1000 // é€‚å½“å‡å°‘ä»»åŠ¡é˜Ÿåˆ—å¤§å°

	workerPool := make(chan struct{}, numWorkers)
	jobQueue := make(chan CrawlJob, jobQueueSize)

	node := &CrawlerNode{
		NodeID:      nodeID,
		DB:          db,
		Client:      client,
		hostLimiter: hostLimiter,
		workerPool:  workerPool,
		jobQueue:    jobQueue,
	}

	// å¯åŠ¨å›ºå®šæ•°é‡çš„workeråç¨‹
	for i := 0; i < numWorkers; i++ {
		go node.crawlWorker()
	}

	return node, nil
}

// GetNextTask ä½¿ç”¨SELECT FOR UPDATEè·å–ä¸‹ä¸€ä¸ªä»»åŠ¡
func (node *CrawlerNode) GetNextTask() (*Book, error) {
	tx, err := node.DB.Begin()
	if err != nil {
		return nil, fmt.Errorf("å¼€å§‹äº‹åŠ¡å¤±è´¥: %v", err)
	}
	defer tx.Rollback()

	// ä½¿ç”¨SELECT FOR UPDATEé”å®šè¡Œ
	query := `SELECT book_number, chapter_count 
			  FROM books 
			  WHERE crawl_status = 0 
			  ORDER BY CAST(book_number AS UNSIGNED) ASC 
			  LIMIT 1 FOR UPDATE`

	var book Book
	err = tx.QueryRow(query).Scan(&book.BookNumber, &book.ChapterCount)
	if err != nil {
		if err == sql.ErrNoRows {
			return nil, nil // æ²¡æœ‰ä»»åŠ¡äº†
		}
		return nil, fmt.Errorf("æŸ¥è¯¢ä»»åŠ¡å¤±è´¥: %v", err)
	}

	// æ›´æ–°çŠ¶æ€ä¸ºçˆ¬å–ä¸­
	updateQuery := `UPDATE books SET crawl_status = 1 WHERE book_number = ?`
	_, err = tx.Exec(updateQuery, book.BookNumber)
	if err != nil {
		return nil, fmt.Errorf("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: %v", err)
	}

	// æäº¤äº‹åŠ¡
	err = tx.Commit()
	if err != nil {
		return nil, fmt.Errorf("æäº¤äº‹åŠ¡å¤±è´¥: %v", err)
	}

	return &book, nil
}

// GenerateChapterURL ç”Ÿæˆå•ä¸ªç« èŠ‚URL
func GenerateChapterURL(bookNumber string, chapterNum int) string {
	return fmt.Sprintf("https://www.a9db770f8.lol/book/%s/%d.html", bookNumber, chapterNum)
}

// CrawlChapter çˆ¬å–å•ä¸ªç« èŠ‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
func (node *CrawlerNode) CrawlChapter(bookNumber string, chapterNum int) (string, string, error) {
	maxRetries := 3
	baseDelay := 1 * time.Second

	var lastErr error
	for attempt := 0; attempt <= maxRetries; attempt++ {
		url := GenerateChapterURL(bookNumber, chapterNum)

		// åˆ›å»ºè¯·æ±‚å¹¶è®¾ç½®å¤´ä¿¡æ¯
		req, err := http.NewRequest("GET", url, nil)
		if err != nil {
			return "", "", fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %v", err)
		}

		// è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
		req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
		req.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8")
		req.Header.Set("Accept-Language", "zh-CN,zh;q=0.9,en;q=0.8")
		req.Header.Set("Accept-Encoding", "gzip, deflate")
		req.Header.Set("Connection", "keep-alive")
		req.Header.Set("Upgrade-Insecure-Requests", "1")

		resp, err := node.Client.Do(req)
		if err != nil {
			lastErr = fmt.Errorf("è¯·æ±‚å¤±è´¥: %v", err)
			if attempt < maxRetries {
				delay := time.Duration(attempt+1) * baseDelay
				fmt.Printf("[%s] ç« èŠ‚ %s-%d è¯·æ±‚å¤±è´¥ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", lastErr
		}
		defer resp.Body.Close()

		// å¤„ç†ä¸åŒçš„HTTPçŠ¶æ€ç 
		switch resp.StatusCode {
		case 200:
			// æˆåŠŸï¼Œç»§ç»­å¤„ç†
			break
		case 404:
			// ç« èŠ‚ä¸å­˜åœ¨ï¼Œä¸é‡è¯•
			return "", "", fmt.Errorf("ç« èŠ‚ä¸å­˜åœ¨ (404)")
		case 403:
			// è¢«å°ç¦ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´åé‡è¯•
			if attempt < maxRetries {
				delay := time.Duration(5*(attempt+1)) * time.Second
				fmt.Printf("[%s] ç« èŠ‚ %s-%d è®¿é—®è¢«æ‹’ç»(403)ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", fmt.Errorf("è®¿é—®è¢«æ‹’ç» (403)")
		case 429:
			// è¯·æ±‚è¿‡å¤šï¼Œç­‰å¾…åé‡è¯•
			if attempt < maxRetries {
				delay := time.Duration(10*(attempt+1)) * time.Second
				fmt.Printf("[%s] ç« èŠ‚ %s-%d è¯·æ±‚è¿‡å¤š(429)ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", fmt.Errorf("è¯·æ±‚è¿‡å¤š (429)")
		case 500, 502, 503, 504:
			// æœåŠ¡å™¨é”™è¯¯ï¼Œé‡è¯•
			if attempt < maxRetries {
				delay := time.Duration(2*(attempt+1)) * time.Second
				fmt.Printf("[%s] ç« èŠ‚ %s-%d æœåŠ¡å™¨é”™è¯¯(%d)ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, resp.StatusCode, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", fmt.Errorf("æœåŠ¡å™¨é”™è¯¯ (%d)", resp.StatusCode)
		default:
			// å…¶ä»–é”™è¯¯
			if attempt < maxRetries {
				delay := time.Duration(attempt+1) * baseDelay
				fmt.Printf("[%s] ç« èŠ‚ %s-%d HTTPé”™è¯¯(%d)ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, resp.StatusCode, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", fmt.Errorf("HTTPçŠ¶æ€ç : %d", resp.StatusCode)
		}

		body, err := ioutil.ReadAll(resp.Body)
		if err != nil {
			return "", "", fmt.Errorf("è¯»å–å“åº”å¤±è´¥: %v", err)
		}

		html := string(body)

		// æå–ç« èŠ‚æ ‡é¢˜
		titleRe := regexp.MustCompile(`<title>([^_]+)`)
		titleMatches := titleRe.FindStringSubmatch(html)
		title := fmt.Sprintf("ç¬¬%dç« ", chapterNum)
		if len(titleMatches) > 1 {
			title = strings.TrimSpace(titleMatches[1])
		}

		// æå–ç« èŠ‚å†…å®¹ - å°è¯•å¤šç§é€‰æ‹©å™¨
		var content string

		// å°è¯•1: id="chaptercontent"
		contentRe1 := regexp.MustCompile(`(?s)<div[^>]*id=["']chaptercontent["'][^>]*>(.*?)</div>`)
		matches1 := contentRe1.FindStringSubmatch(html)
		if len(matches1) > 1 {
			content = matches1[1]
		}

		if content == "" {
			// è°ƒè¯•ï¼šä¿å­˜HTMLåˆ°æ–‡ä»¶æŸ¥çœ‹ç»“æ„
			fmt.Printf("è°ƒè¯•ï¼šä¿å­˜HTMLåˆ° debug_%s_%d.html\n", bookNumber, chapterNum)
			ioutil.WriteFile(fmt.Sprintf("debug_%s_%d.html", bookNumber, chapterNum), body, 0644)
			return title, "", fmt.Errorf("æœªæ‰¾åˆ°ç« èŠ‚å†…å®¹")
		}

		// æ¸…ç†HTMLæ ‡ç­¾
		content = regexp.MustCompile(`<[^>]*>`).ReplaceAllString(content, "")
		content = strings.ReplaceAll(content, "&nbsp;", " ")
		content = strings.ReplaceAll(content, "&#160;", " ")
		content = strings.ReplaceAll(content, "\r", "")
		content = strings.ReplaceAll(content, "\n\n", "\n")
		content = strings.TrimSpace(content)

		return title, content, nil
	}

	return "", "", fmt.Errorf("é‡è¯•å¤±è´¥")
}

// crawlWorker å›ºå®šworkeråç¨‹
func (node *CrawlerNode) crawlWorker() {
	for job := range node.jobQueue {
		// ä¸»æœºçº§é™é€Ÿ
		node.hostLimiter.Wait(context.Background())

		title, content, err := node.crawlChapterOptimized(job.URL, job.BookNumber, job.ChapterNum)

		job.ResultChan <- ChapterResult{
			BookNumber: job.BookNumber,
			ChapterNum: job.ChapterNum,
			Title:      title,
			Content:    content,
			Error:      err,
		}
	}
}

// crawlChapterOptimized ä¼˜åŒ–çš„ç« èŠ‚çˆ¬å–ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
func (node *CrawlerNode) crawlChapterOptimized(url string, bookNumber string, chapterNum int) (string, string, error) {
	maxRetries := 5 // å¢åŠ é‡è¯•æ¬¡æ•°
	baseDelay := 1 * time.Second

	var lastErr error

	for attempt := 0; attempt <= maxRetries; attempt++ {
		// æ£€æŸ¥æ˜¯å¦éœ€è¦å…³é—­
		if node.IsShutdown() {
			return "", "", fmt.Errorf("çˆ¬è™«æ­£åœ¨å…³é—­")
		}

		// æ ¹æ®å°è¯•æ¬¡æ•°è°ƒæ•´è¶…æ—¶æ—¶é—´
		timeout := time.Duration(5+attempt*2) * time.Second // 5s, 7s, 9s, 11s, 13s, 15s
		ctx, cancel := context.WithTimeout(context.Background(), timeout)

		// åˆ›å»ºè¯·æ±‚å¹¶è®¾ç½®å¤´ä¿¡æ¯
		req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
		if err != nil {
			cancel()
			return "", "", fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %v", err)
		}

		// è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
		req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
		req.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8")
		req.Header.Set("Accept-Language", "zh-CN,zh;q=0.9,en;q=0.8")
		req.Header.Set("Connection", "keep-alive")
		req.Header.Set("Cache-Control", "no-cache")

		// å‘é€è¯·æ±‚
		resp, err := node.Client.Do(req)
		cancel() // ç«‹å³å–æ¶ˆcontext

		if err != nil {
			if ctx.Err() == context.DeadlineExceeded {
				lastErr = fmt.Errorf("è¯·æ±‚è¶…æ—¶(%v)", timeout)
			} else {
				lastErr = fmt.Errorf("è¯·æ±‚å¤±è´¥: %v", err)
			}

			if attempt < maxRetries {
				delay := baseDelay * time.Duration(1<<uint(attempt)) // æŒ‡æ•°é€€é¿ï¼š1s, 2s, 4s, 8s, 16s
				fmt.Printf("[%s] âš ï¸  ç« èŠ‚ %s-%d %vï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, lastErr, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", lastErr
		}

		// æ£€æŸ¥HTTPçŠ¶æ€ç å¹¶åˆ†ç±»å¤„ç†
		switch resp.StatusCode {
		case 200:
			// æˆåŠŸï¼Œç»§ç»­å¤„ç†
			break
		case 404:
			// ç« èŠ‚ä¸å­˜åœ¨ï¼Œä¸é‡è¯•
			resp.Body.Close()
			return "", "", fmt.Errorf("ç« èŠ‚ä¸å­˜åœ¨ (404)")
		case 403:
			// è¢«å°ç¦ï¼Œä½¿ç”¨æ›´é•¿çš„ç­‰å¾…æ—¶é—´
			resp.Body.Close()
			if attempt < maxRetries {
				delay := time.Duration(10*(attempt+1)) * time.Second // 10s, 20s, 30s, 40s, 50s
				fmt.Printf("[%s] ğŸš« ç« èŠ‚ %s-%d è®¿é—®è¢«æ‹’ç»(403)ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", fmt.Errorf("è®¿é—®è¢«æ‹’ç» (403)")
		case 429:
			// è¯·æ±‚è¿‡å¤šï¼Œä½¿ç”¨æ›´é•¿çš„ç­‰å¾…æ—¶é—´
			resp.Body.Close()
			if attempt < maxRetries {
				delay := time.Duration(15*(attempt+1)) * time.Second // 15s, 30s, 45s, 60s, 75s
				fmt.Printf("[%s] ğŸš¨ ç« èŠ‚ %s-%d è¯·æ±‚è¿‡å¤š(429)ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", fmt.Errorf("è¯·æ±‚è¿‡å¤š (429)")
		case 500, 502, 503, 504:
			// æœåŠ¡å™¨é”™è¯¯ï¼Œä¸­ç­‰ç­‰å¾…æ—¶é—´
			resp.Body.Close()
			if attempt < maxRetries {
				delay := time.Duration(5*(attempt+1)) * time.Second // 5s, 10s, 15s, 20s, 25s
				fmt.Printf("[%s] ğŸ”´ ç« èŠ‚ %s-%d æœåŠ¡å™¨é”™è¯¯(%d)ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, resp.StatusCode, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", fmt.Errorf("æœåŠ¡å™¨é”™è¯¯ (%d)", resp.StatusCode)
		default:
			// å…¶ä»–HTTPé”™è¯¯
			resp.Body.Close()
			if attempt < maxRetries {
				delay := time.Duration(2*(attempt+1)) * time.Second
				fmt.Printf("[%s] â“ ç« èŠ‚ %s-%d HTTPé”™è¯¯(%d)ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, resp.StatusCode, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", fmt.Errorf("HTTPçŠ¶æ€ç : %d", resp.StatusCode)
		}

		// é™åˆ¶å“åº”ä½“å¤§å°ï¼Œé˜²æ­¢è¯»å–è¶…å¤§æ–‡ä»¶
		limitedBody := http.MaxBytesReader(nil, resp.Body, 2*1024*1024) // é™åˆ¶2MB
		body, err := ioutil.ReadAll(limitedBody)
		resp.Body.Close()

		if err != nil {
			lastErr = fmt.Errorf("è¯»å–å“åº”å¤±è´¥: %v", err)
			if attempt < maxRetries {
				delay := baseDelay * time.Duration(1+attempt)
				fmt.Printf("[%s] ğŸ“– ç« èŠ‚ %s-%d è¯»å–å¤±è´¥ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", lastErr
		}

		html := string(body)

		// éªŒè¯å†…å®¹é•¿åº¦ï¼Œé¿å…è·å–åˆ°ç©ºé¡µé¢
		if len(html) < 100 {
			lastErr = fmt.Errorf("é¡µé¢å†…å®¹è¿‡çŸ­ (%d å­—ç¬¦)", len(html))
			if attempt < maxRetries {
				delay := baseDelay * time.Duration(1+attempt)
				fmt.Printf("[%s] ğŸ“„ ç« èŠ‚ %s-%d å†…å®¹è¿‡çŸ­ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return "", "", lastErr
		}

		// ä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™å¿«é€Ÿæå–æ ‡é¢˜
		title := fmt.Sprintf("ç¬¬%dç« ", chapterNum)
		if titleMatch := titleRegex.FindStringSubmatch(html); len(titleMatch) > 1 {
			title = strings.TrimSpace(titleMatch[1])
		}

		// ä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™å¿«é€Ÿæå–å†…å®¹
		var content string
		if match := contentRegex1.FindStringSubmatch(html); len(match) > 1 {
			content = match[1]
		} else if match := contentRegex2.FindStringSubmatch(html); len(match) > 1 {
			content = match[1]
		} else if matches := contentRegex3.FindAllStringSubmatch(html, -1); len(matches) > 0 {
			// é€‰æ‹©æœ€é•¿çš„å†…å®¹
			for _, match := range matches {
				if len(match[1]) > len(content) {
					content = match[1]
				}
			}
		}

		if content == "" {
			lastErr = fmt.Errorf("æœªæ‰¾åˆ°ç« èŠ‚å†…å®¹")
			if attempt < maxRetries {
				delay := baseDelay * time.Duration(1+attempt)
				fmt.Printf("[%s] ğŸ” ç« èŠ‚ %s-%d å†…å®¹è§£æå¤±è´¥ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return title, "", lastErr
		}

		// ä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™å¿«é€Ÿæ¸…ç†HTML
		content = htmlTagRegex.ReplaceAllString(content, "")
		content = strings.ReplaceAll(content, "&nbsp;", " ")
		content = strings.ReplaceAll(content, "&#160;", " ")
		content = strings.ReplaceAll(content, "\r", "")
		content = strings.ReplaceAll(content, "\n\n", "\n")
		content = strings.TrimSpace(content)

		// æœ€ç»ˆéªŒè¯å†…å®¹é•¿åº¦
		if len(content) < 10 {
			lastErr = fmt.Errorf("ç« èŠ‚å†…å®¹è¿‡çŸ­ (%d å­—ç¬¦)", len(content))
			if attempt < maxRetries {
				delay := baseDelay * time.Duration(1+attempt)
				fmt.Printf("[%s] ğŸ“ ç« èŠ‚ %s-%d æœ€ç»ˆå†…å®¹è¿‡çŸ­ï¼Œ%våé‡è¯• (ç¬¬%dæ¬¡)\n",
					node.NodeID, bookNumber, chapterNum, delay, attempt+1)
				time.Sleep(delay)
				continue
			}
			return title, "", lastErr
		}

		// æˆåŠŸè·å–ç« èŠ‚å†…å®¹
		return title, content, nil
	}

	// æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
	fmt.Printf("[%s] âŒ ç« èŠ‚ %s-%d é‡è¯• %d æ¬¡åæœ€ç»ˆå¤±è´¥: %v\n",
		node.NodeID, bookNumber, chapterNum, maxRetries, lastErr)
	return "", "", fmt.Errorf("é‡è¯• %d æ¬¡åå¤±è´¥: %v", maxRetries, lastErr)
}

// BatchSaveChapters æ‰¹é‡ä¿å­˜ç« èŠ‚åˆ°æ•°æ®åº“
func (node *CrawlerNode) BatchSaveChapters(bookID string, chapters []ChapterResult) error {
	if len(chapters) == 0 {
		return nil
	}

	// æ„å»ºæ‰¹é‡æ’å…¥SQL
	query := `INSERT INTO chapters (book_id, chapter_name, chapter_order, content) VALUES `
	values := []interface{}{}

	for i, chapter := range chapters {
		if i > 0 {
			query += ","
		}
		query += "(?, ?, ?, ?)"
		values = append(values, bookID, chapter.Title, chapter.ChapterNum, chapter.Content)
	}

	query += ` ON DUPLICATE KEY UPDATE content = VALUES(content)`

	_, err := node.DB.Exec(query, values...)
	return err
}

// LogFailedChapter è®°å½•å¤±è´¥ç« èŠ‚ç”¨äºè¡¥çˆ¬ï¼ˆå¢åŠ é”™è¯¯ä¿¡æ¯å’Œé‡è¯•æ¬¡æ•°ï¼‰
func (node *CrawlerNode) LogFailedChapter(bookNumber string, chapterNum int, url string, errorMsg string) error {
	// å…ˆæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥å¤±è´¥è®°å½•
	checkQuery := `SELECT retry_count FROM failed_chapters WHERE book_number = ? AND chapter_number = ?`
	var retryCount int
	err := node.DB.QueryRow(checkQuery, bookNumber, chapterNum).Scan(&retryCount)

	if err == sql.ErrNoRows {
		// ä¸å­˜åœ¨ï¼Œæ’å…¥æ–°è®°å½•
		query := `INSERT INTO failed_chapters (book_number, chapter_number, url, error_message, retry_count, failed_at, last_retry_at) 
				  VALUES (?, ?, ?, ?, 1, NOW(), NOW())`
		_, err = node.DB.Exec(query, bookNumber, chapterNum, url, errorMsg)
		return err
	} else if err == nil {
		// å·²å­˜åœ¨ï¼Œæ›´æ–°é‡è¯•æ¬¡æ•°å’Œé”™è¯¯ä¿¡æ¯
		updateQuery := `UPDATE failed_chapters 
						SET retry_count = retry_count + 1, 
							error_message = ?, 
							last_retry_at = NOW() 
						WHERE book_number = ? AND chapter_number = ?`
		_, err = node.DB.Exec(updateQuery, errorMsg, bookNumber, chapterNum)
		return err
	}

	return err
}

// SaveChapter ä¿å­˜ç« èŠ‚åˆ°æ•°æ®åº“
func (node *CrawlerNode) SaveChapter(bookID string, chapterTitle string, content string, chapterOrder int) error {
	query := `INSERT INTO chapters (book_id, chapter_name, chapter_order, content) 
			  VALUES (?, ?, ?, ?) 
			  ON DUPLICATE KEY UPDATE content = VALUES(content)`

	_, err := node.DB.Exec(query, bookID, chapterTitle, chapterOrder, content)
	return err
}

// AsyncDBSaver å¼‚æ­¥æ•°æ®åº“ä¿å­˜å™¨
type AsyncDBSaver struct {
	saveChan chan []ChapterResult
	node     *CrawlerNode
	wg       sync.WaitGroup
}

// NewAsyncDBSaver åˆ›å»ºå¼‚æ­¥æ•°æ®åº“ä¿å­˜å™¨
func NewAsyncDBSaver(node *CrawlerNode) *AsyncDBSaver {
	saver := &AsyncDBSaver{
		saveChan: make(chan []ChapterResult, 10), // ç¼“å†²10ä¸ªæ‰¹æ¬¡
		node:     node,
	}

	// å¯åŠ¨åå°ä¿å­˜åç¨‹
	saver.wg.Add(1)
	go saver.saveWorker()

	return saver
}

// saveWorker åå°ä¿å­˜å·¥ä½œåç¨‹
func (s *AsyncDBSaver) saveWorker() {
	defer s.wg.Done()

	for chapters := range s.saveChan {
		if len(chapters) == 0 {
			continue
		}

		bookNumber := chapters[0].BookNumber // ä»ç« èŠ‚ç»“æœä¸­è·å–ä¹¦å·
		err := s.node.BatchSaveChapters(bookNumber, chapters)
		if err != nil {
			fmt.Printf("[%s] ğŸ”´ å¼‚æ­¥æ‰¹é‡ä¿å­˜å¤±è´¥: %v\n", s.node.NodeID, err)
		} else {
			fmt.Printf("[%s] ğŸ’¾ å¼‚æ­¥ä¿å­˜ %d ç« å®Œæˆ\n", s.node.NodeID, len(chapters))
		}
	}
}

// Save å¼‚æ­¥ä¿å­˜ç« èŠ‚
func (s *AsyncDBSaver) Save(chapters []ChapterResult) {
	if len(chapters) == 0 {
		return
	}

	// åˆ›å»ºç« èŠ‚å‰¯æœ¬é¿å…æ•°æ®ç«äº‰
	chaptersCopy := make([]ChapterResult, len(chapters))
	copy(chaptersCopy, chapters)

	select {
	case s.saveChan <- chaptersCopy:
		// æˆåŠŸå‘é€åˆ°ä¿å­˜é˜Ÿåˆ—
	default:
		// é˜Ÿåˆ—æ»¡äº†ï¼ŒåŒæ­¥ä¿å­˜ï¼ˆå¤‡ç”¨ç­–ç•¥ï¼‰
		fmt.Printf("[%s] âš ï¸  å¼‚æ­¥é˜Ÿåˆ—æ»¡ï¼ŒåŒæ­¥ä¿å­˜ %d ç« \n", s.node.NodeID, len(chapters))
		if len(chapters) > 0 {
			s.node.BatchSaveChapters(chapters[0].BookNumber, chapters)
		}
	}
}

// Close å…³é—­å¼‚æ­¥ä¿å­˜å™¨
func (s *AsyncDBSaver) Close() {
	close(s.saveChan)
	s.wg.Wait()
}

// ProcessBook å¤„ç†æ•´æœ¬ä¹¦ - Workeræ± é«˜å¸¦å®½ç‰ˆæœ¬
func (node *CrawlerNode) ProcessBook(book *Book) error {
	fmt.Printf("[%s] ğŸ“– å¼€å§‹å¤„ç†ä¹¦ç± %s (å…±%dç« )\n", node.NodeID, book.BookNumber, book.ChapterCount)

	// åˆ›å»ºå¼‚æ­¥æ•°æ®åº“ä¿å­˜å™¨
	dbSaver := NewAsyncDBSaver(node)
	defer dbSaver.Close()

	// ç»“æœæ”¶é›†channel
	resultChan := make(chan ChapterResult, book.ChapterCount)

	// è¿›åº¦ç»Ÿè®¡
	var (
		totalCompleted int32
		totalSuccess   int32
		totalFailed    int32
	)

	// å¯åŠ¨è¿›åº¦ç›‘æ§åç¨‹ - å‡å°‘åˆ·å±é¢‘ç‡
	progressTicker := time.NewTicker(4 * time.Second) // æ¯4ç§’æ‰“å°ä¸€æ¬¡
	defer progressTicker.Stop()

	var lastCompleted int32
	var lastPrintTime time.Time
	stuckCount := 0

	go func() {
		for range progressTicker.C {
			completed := atomic.LoadInt32(&totalCompleted)
			success := atomic.LoadInt32(&totalSuccess)
			failed := atomic.LoadInt32(&totalFailed)

			// æ£€æµ‹è¿›åº¦æ˜¯å¦å¡ä½
			if completed == lastCompleted && completed > 0 {
				stuckCount++
				if stuckCount >= 2 { // 8ç§’æ²¡è¿›åº¦æŠ¥è­¦
					fmt.Printf("[%s] âš ï¸  æ£€æµ‹åˆ°æ…¢ä»»åŠ¡é˜»å¡ï¼Œå½“å‰: %d/%d\n",
						node.NodeID, completed, book.ChapterCount)
				}
			} else {
				stuckCount = 0
			}

			// é¿å…é‡å¤åˆ·å±ï¼šåªåœ¨è¿›åº¦æœ‰å˜åŒ–æˆ–è¶…è¿‡5ç§’æœªæ‰“å°æ—¶è¾“å‡º
			now := time.Now()
			shouldPrint := completed != lastCompleted || now.Sub(lastPrintTime) > 5*time.Second

			if completed > 0 && shouldPrint {
				successRate := float64(success) / float64(completed) * 100
				progress := float64(completed) / float64(book.ChapterCount) * 100

				fmt.Printf("[%s] ğŸ“Š è¿›åº¦: %d/%d (%.1f%%) æˆåŠŸ:%d å¤±è´¥:%d æˆåŠŸç‡:%.1f%%\n",
					node.NodeID, completed, book.ChapterCount, progress, success, failed, successRate)

				// æ˜¾ç¤ºè¿æ¥çŠ¶æ€ (æ¯10ç§’æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†ä¿¡æ¯)
				if now.Sub(lastPrintTime) > 10*time.Second {
					fmt.Printf("[%s] ğŸŒ è¿æ¥çŠ¶æ€: å…¨éƒ¨ç›´è¿æ¨¡å¼\n", node.NodeID)
				}

				lastPrintTime = now
			}

			lastCompleted = completed
		}
	}()

	// ä½¿ç”¨Workeræ± åˆ†å‘ä»»åŠ¡ - ä¿å®ˆæ¨¡å¼ + ä¸­æ–­æ¢å¤
	baseURL := "https://www.a9db770f8.lol/book/" + book.BookNumber + "/"
	fmt.Printf("[%s] ğŸš€ åˆ†å‘ %d ä¸ªä»»åŠ¡åˆ°100ä¸ªWorkeræ±  (ä¿å®ˆæ¨¡å¼ï¼Œæ›´ç¨³å®š)...\n", node.NodeID, book.ChapterCount)

	// æ£€æŸ¥å·²å®Œæˆçš„ç« èŠ‚ï¼Œé¿å…é‡å¤çˆ¬å–
	completedChapters := make(map[int]bool)
	checkQuery := `SELECT chapter_order FROM chapters WHERE book_id = ?`
	rows, err := node.DB.Query(checkQuery, book.BookNumber)
	if err == nil {
		for rows.Next() {
			var chapterOrder int
			if rows.Scan(&chapterOrder) == nil {
				completedChapters[chapterOrder] = true
			}
		}
		rows.Close()
		fmt.Printf("[%s] ğŸ“‹ å‘ç°å·²å®Œæˆç« èŠ‚: %d ä¸ªï¼Œè·³è¿‡é‡å¤çˆ¬å–\n", node.NodeID, len(completedChapters))
	}

	// å¿«é€Ÿåˆ†å‘æœªå®Œæˆçš„ç« èŠ‚ä»»åŠ¡åˆ°workeræ± 
	go func() {
		for chapterNum := 1; chapterNum <= book.ChapterCount; chapterNum++ {
			// è·³è¿‡å·²å®Œæˆçš„ç« èŠ‚
			if completedChapters[chapterNum] {
				// å‘é€ä¸€ä¸ªæˆåŠŸç»“æœï¼Œä¿è¯è®¡æ•°æ­£ç¡®
				go func(num int) {
					resultChan <- ChapterResult{
						BookNumber: book.BookNumber,
						ChapterNum: num,
						Title:      fmt.Sprintf("ç¬¬%dç« ", num),
						Content:    "å·²å­˜åœ¨", // æ ‡è®°ä¸ºå·²å­˜åœ¨
						Error:      nil,
					}
				}(chapterNum)
				continue
			}

			job := CrawlJob{
				BookNumber: book.BookNumber,
				ChapterNum: chapterNum,
				URL:        baseURL + fmt.Sprintf("%d.html", chapterNum),
				ResultChan: resultChan,
			}

			// å¿«é€Ÿéé˜»å¡å‘é€
			select {
			case node.jobQueue <- job:
				// ä»»åŠ¡æˆåŠŸåŠ å…¥é˜Ÿåˆ—
			default:
				// é˜Ÿåˆ—æ»¡äº†ç¨ç­‰ç‰‡åˆ»
				time.Sleep(1 * time.Millisecond)
				node.jobQueue <- job
			}
		}
	}()

	// æ”¶é›†ç»“æœ
	var chapters []ChapterResult
	successCount := 0
	failedCount := 0

	// åˆç†è¶…æ—¶è®¾ç½® - ç»™è¶³æ—¶é—´å®Œæˆï¼Œä½†é¿å…æ— é™ç­‰å¾…
	timeoutDuration := time.Duration(book.ChapterCount/50+30) * time.Second // å¢åŠ è¶…æ—¶æ—¶é—´
	if timeoutDuration > 300*time.Second {
		timeoutDuration = 300 * time.Second // æœ€å¤š5åˆ†é’Ÿ
	}
	timeout := time.NewTimer(timeoutDuration)
	defer timeout.Stop()

	for i := 0; i < book.ChapterCount; i++ {
		select {
		case result := <-resultChan:
			atomic.AddInt32(&totalCompleted, 1)

			if result.Error != nil {
				atomic.AddInt32(&totalFailed, 1)
				failedCount++
				if failedCount <= 20 { // å…è®¸æ›´å¤šé”™è¯¯æ—¥å¿—
					fmt.Printf("[%s] âŒ ç« èŠ‚ %s-%d: %v\n", node.NodeID, book.BookNumber, result.ChapterNum, result.Error)
				}

				// è®°å½•å¤±è´¥ç« èŠ‚ï¼ŒåŒ…å«é”™è¯¯ä¿¡æ¯
				url := baseURL + fmt.Sprintf("%d.html", result.ChapterNum)
				node.LogFailedChapter(book.BookNumber, result.ChapterNum, url, result.Error.Error())
				continue
			}

			// å¤„ç†å·²å­˜åœ¨çš„ç« èŠ‚
			if result.Content == "å·²å­˜åœ¨" {
				atomic.AddInt32(&totalSuccess, 1)
				successCount++
				continue
			}

			if result.Content == "" {
				atomic.AddInt32(&totalFailed, 1)
				failedCount++
				url := baseURL + fmt.Sprintf("%d.html", result.ChapterNum)
				node.LogFailedChapter(book.BookNumber, result.ChapterNum, url, "ç« èŠ‚å†…å®¹ä¸ºç©º")
				continue
			}

			atomic.AddInt32(&totalSuccess, 1)
			chapters = append(chapters, result)
			successCount++

			// è‡ªé€‚åº”æ‰¹é‡ä¿å­˜ - æ ¹æ®ç« èŠ‚æ•°è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°
			batchSize := 50
			if book.ChapterCount > 1000 {
				batchSize = 100 // å¤§ä¹¦ç”¨æ›´å¤§æ‰¹æ¬¡
			} else if book.ChapterCount < 200 {
				batchSize = 20 // å°ä¹¦ç”¨å°æ‰¹æ¬¡
			}

			if len(chapters) >= batchSize {
				dbSaver.Save(chapters)
				chapters = chapters[:0]
			}

		case <-timeout.C:
			fmt.Printf("[%s] â° ä¹¦ç± %s å¤„ç†è¶…æ—¶ï¼Œå·²å®Œæˆ %d/%d ç« \n",
				node.NodeID, book.BookNumber, i, book.ChapterCount)
			goto finish
		}
	}

finish:
	// ä¿å­˜å‰©ä½™ç« èŠ‚ - å…³é”®ï¼ç¡®ä¿ä¸­æ–­æ—¶ä¸ä¸¢å¤±æ•°æ®
	if len(chapters) > 0 {
		fmt.Printf("[%s] ğŸ’¾ ä¿å­˜å‰©ä½™ %d ç« èŠ‚...\n", node.NodeID, len(chapters))
		dbSaver.Save(chapters)
	}

	fmt.Printf("[%s] ğŸ“¥ ç­‰å¾…æ•°æ®åº“ä¿å­˜å®Œæˆ...\n", node.NodeID)

	fmt.Printf("[%s] âœ… ä¹¦ç± %s å¤„ç†å®Œæˆ: %d/%d ç« æˆåŠŸ (æˆåŠŸç‡: %.1f%%)\n",
		node.NodeID, book.BookNumber, successCount, book.ChapterCount,
		float64(successCount)/float64(book.ChapterCount)*100)

	return nil
}

// RetryFailedChapters æ™ºèƒ½è¡¥çˆ¬å¤±è´¥çš„ç« èŠ‚
func (node *CrawlerNode) RetryFailedChapters() error {
	// è·å–å¤±è´¥çš„ç« èŠ‚ï¼Œä¼˜å…ˆè¡¥çˆ¬é‡è¯•æ¬¡æ•°å°‘çš„ã€æ—¶é—´è¾ƒæ—©çš„ç« èŠ‚
	// è·³è¿‡é‡è¯•æ¬¡æ•°è¿‡å¤šçš„ç« èŠ‚ï¼ˆå¯èƒ½æ˜¯æ°¸ä¹…æ€§é”™è¯¯ï¼‰
	query := `SELECT book_number, chapter_number, url, retry_count, error_message 
			  FROM failed_chapters 
			  WHERE retry_count <= 10 
			  ORDER BY retry_count ASC, failed_at ASC 
			  LIMIT 50` // å‡å°‘æ‰¹æ¬¡å¤§å°ï¼Œé¿å…é˜»å¡è¿‡ä¹…

	rows, err := node.DB.Query(query)
	if err != nil {
		return fmt.Errorf("æŸ¥è¯¢å¤±è´¥ç« èŠ‚å¤±è´¥: %v", err)
	}
	defer rows.Close()

	var successCount, skipCount int

	for rows.Next() {
		// æ£€æŸ¥æ˜¯å¦éœ€è¦å…³é—­
		if node.IsShutdown() {
			fmt.Printf("[%s] ğŸ›‘ è¡¥çˆ¬ä¸­æ–­ï¼Œçˆ¬è™«æ­£åœ¨å…³é—­\n", node.NodeID)
			break
		}

		var bookNumber, url, errorMsg string
		var chapterNum, retryCount int

		err = rows.Scan(&bookNumber, &chapterNum, &url, &retryCount, &errorMsg)
		if err != nil {
			continue
		}

		// æ ¹æ®ä¹‹å‰çš„é”™è¯¯ç±»å‹å†³å®šæ˜¯å¦è·³è¿‡
		if strings.Contains(errorMsg, "ç« èŠ‚ä¸å­˜åœ¨ (404)") {
			// 404é”™è¯¯è¯´æ˜ç« èŠ‚çœŸçš„ä¸å­˜åœ¨ï¼Œè·³è¿‡
			skipCount++
			fmt.Printf("[%s] â­ï¸  è·³è¿‡ä¸å­˜åœ¨çš„ç« èŠ‚: %s-%d (404)\n", node.NodeID, bookNumber, chapterNum)
			continue
		}

		// æ ¹æ®é‡è¯•æ¬¡æ•°å¢åŠ å»¶è¿Ÿï¼Œé¿å…é¢‘ç¹é‡è¯•
		if retryCount > 1 {
			delay := time.Duration(retryCount) * 2 * time.Second // 2s, 4s, 6s, 8s...
			fmt.Printf("[%s] â³ ç« èŠ‚ %s-%d å·²é‡è¯• %d æ¬¡ï¼Œç­‰å¾… %v åè¡¥çˆ¬\n",
				node.NodeID, bookNumber, chapterNum, retryCount, delay)
			time.Sleep(delay)
		}

		// å°è¯•é‡æ–°çˆ¬å–
		fmt.Printf("[%s] ğŸ”„ è¡¥çˆ¬ç« èŠ‚ %s-%d (ç¬¬ %d æ¬¡å°è¯•)\n", node.NodeID, bookNumber, chapterNum, retryCount+1)
		title, content, err := node.crawlChapterOptimized(url, bookNumber, chapterNum)

		if err == nil && content != "" {
			// æˆåŠŸäº†ï¼Œä¿å­˜å¹¶åˆ é™¤å¤±è´¥è®°å½•
			err = node.SaveChapter(bookNumber, title, content, chapterNum)
			if err == nil {
				// åˆ é™¤å¤±è´¥è®°å½•
				deleteQuery := `DELETE FROM failed_chapters WHERE book_number = ? AND chapter_number = ?`
				node.DB.Exec(deleteQuery, bookNumber, chapterNum)
				successCount++
				fmt.Printf("[%s] âœ… è¡¥çˆ¬æˆåŠŸ: %s-%d\n", node.NodeID, bookNumber, chapterNum)
			} else {
				// ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥ï¼Œæ›´æ–°å¤±è´¥è®°å½•
				node.LogFailedChapter(bookNumber, chapterNum, url, fmt.Sprintf("ä¿å­˜å¤±è´¥: %v", err))
			}
		} else {
			// è¡¥çˆ¬ä»ç„¶å¤±è´¥ï¼Œæ›´æ–°å¤±è´¥è®°å½•
			if err != nil {
				node.LogFailedChapter(bookNumber, chapterNum, url, err.Error())
			} else {
				node.LogFailedChapter(bookNumber, chapterNum, url, "è¡¥çˆ¬åå†…å®¹ä»ä¸ºç©º")
			}
		}

		// è¡¥çˆ¬é—´éš”ï¼Œé¿å…è¿‡äºé¢‘ç¹
		time.Sleep(100 * time.Millisecond)
	}

	if successCount > 0 || skipCount > 0 {
		fmt.Printf("[%s] ğŸ“Š è¡¥çˆ¬å®Œæˆ: æˆåŠŸ %d ä¸ªï¼Œè·³è¿‡ %d ä¸ªç« èŠ‚\n", node.NodeID, successCount, skipCount)
	} else {
		fmt.Printf("[%s] ğŸ“­ æ²¡æœ‰éœ€è¦è¡¥çˆ¬çš„ç« èŠ‚\n", node.NodeID)
	}

	return nil
}

// MarkBookCompleted æ ‡è®°ä¹¦ç±å®Œæˆ
func (node *CrawlerNode) MarkBookCompleted(bookNumber string, success bool) error {
	status := 2 // æˆåŠŸ
	if !success {
		status = 3 // å¤±è´¥
	}

	query := `UPDATE books SET crawl_status = ? WHERE book_number = ?`
	_, err := node.DB.Exec(query, status, bookNumber)
	return err
}

// SetShutdown è®¾ç½®ä¼˜é›…å…³é—­æ ‡å¿—
func (node *CrawlerNode) SetShutdown() {
	atomic.StoreInt32(&node.shutdown, 1)
	fmt.Printf("[%s] ğŸ“ å·²è®¾ç½®å…³é—­æ ‡å¿—ï¼Œç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ...\n", node.NodeID)
}

// IsShutdown æ£€æŸ¥æ˜¯å¦éœ€è¦å…³é—­
func (node *CrawlerNode) IsShutdown() bool {
	return atomic.LoadInt32(&node.shutdown) == 1
}

// Run è¿è¡Œçˆ¬è™«èŠ‚ç‚¹
func (node *CrawlerNode) Run() {
	fmt.Printf("[%s] çˆ¬è™«èŠ‚ç‚¹å¯åŠ¨\n", node.NodeID)

	// æ˜¾ç¤ºè¿æ¥é…ç½®ä¿¡æ¯
	fmt.Printf("[%s] ğŸŒ è¿æ¥é…ç½®: å…¨éƒ¨ç›´è¿æ¨¡å¼\n", node.NodeID)

	for {
		// æ£€æŸ¥å…³é—­æ ‡å¿—
		if node.IsShutdown() {
			fmt.Printf("[%s] ğŸ›‘ æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œåœæ­¢å¤„ç†æ–°ä»»åŠ¡\n", node.NodeID)
			break
		}

		// è·å–ä»»åŠ¡
		book, err := node.GetNextTask()
		if err != nil {
			fmt.Printf("[%s] è·å–ä»»åŠ¡å¤±è´¥: %v\n", node.NodeID, err)
			time.Sleep(5 * time.Second)
			continue
		}

		if book == nil {
			fmt.Printf("[%s] æ²¡æœ‰æ›´å¤šä»»åŠ¡ï¼Œå¼€å§‹è¡¥çˆ¬å¤±è´¥ç« èŠ‚\n", node.NodeID)
			if !node.IsShutdown() { // å…³é—­æ—¶ä¸æ‰§è¡Œè¡¥çˆ¬
				node.RetryFailedChapters()
			}
			time.Sleep(10 * time.Second)
			continue
		}

		// å†æ¬¡æ£€æŸ¥å…³é—­æ ‡å¿—ï¼ˆå¤„ç†ä»»åŠ¡å‰ï¼‰
		if node.IsShutdown() {
			fmt.Printf("[%s] ğŸ›‘ å…³é—­ä¿¡å·æ£€æµ‹åˆ°ï¼Œè·³è¿‡ä¹¦ç± %s\n", node.NodeID, book.BookNumber)
			break
		}

		// å¤„ç†ä»»åŠ¡
		fmt.Printf("[%s] ğŸ“– å¼€å§‹å¤„ç†ä¹¦ç± %s (æ”¯æŒä¸­æ–­æ¢å¤)\n", node.NodeID, book.BookNumber)
		err = node.ProcessBook(book)
		success := err == nil

		// æ›´æ–°ä»»åŠ¡çŠ¶æ€
		err = node.MarkBookCompleted(book.BookNumber, success)
		if err != nil {
			fmt.Printf("[%s] æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: %v\n", node.NodeID, err)
		}

		if success {
			fmt.Printf("[%s] âœ… ä¹¦ç± %s å¤„ç†å®Œæˆ\n", node.NodeID, book.BookNumber)
		} else {
			fmt.Printf("[%s] âŒ ä¹¦ç± %s å¤„ç†å¤±è´¥\n", node.NodeID, book.BookNumber)
		}

		// å¤„ç†å®Œä¸€æœ¬ä¹¦åå†æ¬¡æ£€æŸ¥å…³é—­æ ‡å¿—
		if node.IsShutdown() {
			fmt.Printf("[%s] ğŸ›‘ å¤„ç†å®Œå½“å‰ä¹¦ç±ï¼Œå‡†å¤‡å®‰å…¨é€€å‡º\n", node.NodeID)
			break
		}
	}

	fmt.Printf("[%s] ğŸ çˆ¬è™«èŠ‚ç‚¹å·²å®‰å…¨å…³é—­\n", node.NodeID)
}

func main() {
	// ç”ŸæˆèŠ‚ç‚¹IDï¼ˆå¯ä»¥ç”¨ä¸»æœºå+è¿›ç¨‹IDï¼‰
	hostname, _ := os.Hostname()
	nodeID := fmt.Sprintf("%s-%d", hostname, os.Getpid())

	node, err := NewCrawlerNode(nodeID)
	if err != nil {
		fmt.Printf("åˆ›å»ºçˆ¬è™«èŠ‚ç‚¹å¤±è´¥: %v\n", err)
		return
	}
	defer node.DB.Close()

	// è®¾ç½®ä¿¡å·å¤„ç† - ä¼˜é›…å…³é—­
	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)

	// å¯åŠ¨çˆ¬è™«èŠ‚ç‚¹ï¼ˆå¼‚æ­¥ï¼‰
	done := make(chan bool)
	go func() {
		node.Run()
		done <- true
	}()

	// ç­‰å¾…ä¿¡å·æˆ–ç¨‹åºç»“æŸ
	select {
	case <-sigChan:
		fmt.Printf("\n[%s] ğŸ›‘ æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...\n", nodeID)
		node.SetShutdown() // è®¾ç½®å…³é—­æ ‡å¿—

		// ç»™ç¨‹åº10ç§’æ—¶é—´å®Œæˆå½“å‰ä»»åŠ¡
		select {
		case <-done:
			fmt.Printf("[%s] âœ… ç¨‹åºæ­£å¸¸ç»“æŸ\n", nodeID)
		case <-time.After(10 * time.Second):
			fmt.Printf("[%s] â° è¶…æ—¶å¼ºåˆ¶é€€å‡º\n", nodeID)
		}
	case <-done:
		fmt.Printf("[%s] âœ… ç¨‹åºæ­£å¸¸ç»“æŸ\n", nodeID)
	}
}
