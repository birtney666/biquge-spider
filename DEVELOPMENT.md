# 笔趣阁爬虫开发文档

## 项目概述

**项目名称**: biquge-spider  
**版本**: 1.0.1  
**开发语言**: Go 1.23.0  
**项目类型**: 小说网站爬虫系统

## 开发历程

### 版本 1.0.0 (2025-08-29 00:14)
**提交者**: Birtney  
**提交ID**: aef7d5f

**初始版本特性**:
- 项目初始化
- 创建基础Go模块 (`go.mod`, `go.sum`)
- 实现初版爬虫逻辑 (`tes.go` - 1109行)

### 版本 1.0.1 (2025-08-29 13:05)  
**提交者**: root  
**提交ID**: c10a6b4

**重大重构和优化**:
- **模块化重构**: 将单文件1109行代码重构为多个模块
- **统一配置管理**: 实现基于YAML的配置文件系统
- **优化URL生成**: 使用模板化的URL生成逻辑
- **删除硬编码**: 移除硬编码配置，改为配置驱动

**新增文件**:
- `README.md` (116行) - 项目说明文档
- `config.yaml` (43行) - 统一配置文件
- `config.go` (129行) - 配置管理模块
- `main.go` (52行) - 程序入口
- `crawler.go` (412行) - 爬虫核心逻辑
- `database.go` (224行) - 数据库操作
- `client.go` (237行) - HTTP客户端
- `task.go` (72行) - 异步任务管理

## 技术架构

### 核心模块

#### 1. 配置管理 (`config.go`)
- **YAML配置文件支持**
- **时间配置转换**: 秒转换为`time.Duration`
- **URL模板化生成**: 支持书籍和章节URL动态生成
- **配置验证**: 配置文件加载和解析

#### 2. 爬虫引擎 (`crawler.go`)
- **分布式节点架构**: 支持多节点协同爬取
- **工作池模式**: 可配置工作协程数量
- **限流控制**: 基于令牌桶的请求频率控制
- **智能批处理**: 根据章节数量动态调整批次大小
- **进度监控**: 实时显示爬取进度和成功率
- **优雅关闭**: 支持信号中断和安全退出
- **失败重试**: 智能补爬失败章节

#### 3. 数据库层 (`database.go`)
- **MySQL连接池**: 可配置连接数和生命周期
- **事务安全**: 使用SELECT FOR UPDATE避免任务重复
- **批量操作**: 支持章节批量保存
- **失败追踪**: 记录和管理失败章节
- **断点续传**: 支持爬取中断恢复

#### 4. HTTP客户端 (`client.go`)
- **HTTP/2支持**: 强制启用HTTP/2协议
- **连接复用**: 配置连接池和Keep-Alive
- **智能重试**: 基于状态码的差异化重试策略
- **内容提取**: 多正则表达式匹配章节内容
- **错误处理**: 详细的错误分类和处理

#### 5. 异步任务 (`task.go`)
- **异步保存**: 非阻塞数据库写入
- **队列缓冲**: 防止数据库IO阻塞爬取
- **故障转移**: 队列满时自动切换同步模式

### 关键特性

#### 性能优化
- **并发控制**: 100个工作协程并发爬取
- **连接池**: HTTP连接复用，最大10000空闲连接
- **批量处理**: 50章节批量保存到数据库
- **限流保护**: 100 QPS限制，150突发容量

#### 容错机制
- **多级重试**: 最多5次重试，指数退避延迟
- **失败记录**: 详细记录失败原因和重试次数
- **状态码处理**: 针对不同HTTP状态码的专门处理逻辑
- **超时控制**: 动态计算任务超时时间

#### 监控和日志
- **实时进度**: 每4秒更新爬取进度
- **状态监控**: 检测任务阻塞和慢任务
- **详细日志**: 包含emoji的友好日志输出
- **节点标识**: 多节点环境下的主机名标识

## 配置说明

### 网站配置
```yaml
site:
  base_url: "https://www.0d6f590b.sbs"
  book_url_template: "/book/{book_number}/"
  chapter_url_template: "/book/{book_number}/{chapter_num}.html"
```

### 数据库配置
```yaml
database:
  dsn: "root:password@tcp(localhost:3306)/novel?charset=utf8mb4"
  max_open_conns: 200
  max_idle_conns: 100
  conn_max_lifetime_minutes: 10
```

### 爬虫配置
```yaml
crawler:
  num_workers: 100          # 工作协程数
  job_queue_size: 1000      # 任务队列大小
  rate_limit: 100           # 请求频率限制
  rate_burst: 150           # 突发请求容量
  max_retries: 5            # 最大重试次数
  base_delay_seconds: 1     # 基础延迟时间
  batch_size: 50            # 批处理大小
  progress_ticker_seconds: 4 # 进度更新间隔
```

## 数据库设计

### 核心表结构
- **books表**: 存储书籍信息和爬取状态
  - `book_number`: 书籍编号
  - `chapter_count`: 章节总数
  - `crawl_status`: 爬取状态 (0:待爬取, 1:进行中, 2:完成, 3:失败)

- **chapters表**: 存储章节内容
  - `book_id`: 书籍ID
  - `chapter_name`: 章节标题
  - `chapter_order`: 章节顺序
  - `content`: 章节内容

- **failed_chapters表**: 失败章节追踪
  - `book_number`: 书籍编号
  - `chapter_number`: 章节编号
  - `url`: 失败URL
  - `error_message`: 错误信息
  - `retry_count`: 重试次数
  - `failed_at`: 失败时间
  - `last_retry_at`: 最后重试时间

## 开发依赖

```go
require (
    github.com/go-sql-driver/mysql v1.9.3  // MySQL驱动
    golang.org/x/net v0.17.0               // HTTP/2支持
    golang.org/x/time v0.12.0              // 限流器
    gopkg.in/yaml.v3 v3.0.1                // YAML解析
)
```

## 运行流程

1. **启动阶段**: 加载配置 → 创建节点 → 启动工作池
2. **任务分发**: 从数据库获取待爬取书籍 → 生成章节任务
3. **并发爬取**: 多协程并发处理 → 限流控制 → 内容提取
4. **结果处理**: 异步批量保存 → 失败记录 → 进度更新
5. **补爬机制**: 智能重试失败章节 → 跳过不存在章节
6. **优雅关闭**: 信号处理 → 完成当前任务 → 安全退出

## 关键改进

### 从1.0.0到1.0.1的主要改进

1. **代码结构优化**
   - 单文件1109行 → 模块化7个文件
   - 硬编码配置 → YAML配置文件
   - 紧耦合 → 松耦合设计

2. **性能提升**
   - 添加HTTP连接池优化
   - 实现异步数据库保存
   - 增加智能批处理机制

3. **稳定性增强**
   - 完善错误处理机制
   - 添加失败章节补爬功能
   - 实现优雅关闭机制

4. **可维护性**
   - 统一配置文件管理
   - 模块化代码结构
   - 详细的日志和监控

## 未来规划

基于当前架构，可以考虑的扩展方向:
- 添加代理池支持 (已有proxy_verify目录)
- 实现分布式任务调度
- 添加Web管理界面
- 支持更多网站适配
- 实现爬取数据分析和报表

## 开发说明

本项目采用Go语言开发，使用现代化的并发模式和配置管理。代码结构清晰，具备良好的扩展性和维护性。通过配置文件可以灵活调整爬虫参数，适应不同的爬取需求。